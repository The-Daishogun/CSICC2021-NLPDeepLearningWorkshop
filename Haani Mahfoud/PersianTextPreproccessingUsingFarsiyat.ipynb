{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": " پیش پردازش متون فارسی با استفاده از فارسی‌یار.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDlYQe2dQOu0"
      },
      "source": [
        "# پیش پردازش متون فارسی با استفاده از فارسی‌یار"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yW6cmlZQOvG"
      },
      "source": [
        "#https://app.text-mining.ir/CustomerPanel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEhPc2mAQOvJ"
      },
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "def callApi(url, data, tokenKey):\n",
        "    headers = {\n",
        "        'Content-Type': \"application/json\",\n",
        "        'Authorization': \"Bearer \" + tokenKey,\n",
        "        'Cache-Control': \"no-cache\"\n",
        "    }\n",
        "    response = requests.request(\"POST\", url, data=data.encode(\"utf-8\"), headers=headers)\n",
        "    return response.text\n",
        "\n",
        "##################### Get Token by Api Key ##########################\n",
        "\n",
        "\n",
        "baseUrl = \"http://api.text-mining.ir/api/\"\n",
        "url = baseUrl + \"Token/GetToken\"\n",
        "querystring = {\"apikey\":\"51f75c8d-367d-eb11-80ee-98ded002619b\"}\n",
        "response = requests.request(\"GET\", url, params=querystring)\n",
        "data = json.loads(response.text)\n",
        "tokenKey = data['token']\n",
        "#print (tokenKey)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IrQozWIQOvL"
      },
      "source": [
        "# (Normalizer) نرمال ساز متن"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K1RtaQ6QOvM",
        "outputId": "3a9ff5ab-b134-4d9c-8f7e-3e4458a75039"
      },
      "source": [
        "baseUrl = \"http://api.text-mining.ir/api/\"\n",
        "url =  baseUrl + \"PreProcessing/NormalizePersianWord\"\n",
        "text = \"ك - ک - می خواهم - ایده ی خوب\"\n",
        "payload = u\"{\\\"text\\\":\\\"\"+text+\"\\\", \\\"refineSeparatedAffix\\\":true}\"\n",
        "print(callApi(url, payload, tokenKey))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ک- ک- می‌خواهم- ایده‌ی خوب\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evxxeSomQOvR"
      },
      "source": [
        "# (Sentence Splitter and Tokenizer) تقطیع جملات و واژه ها"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4zGvuLeQOvT",
        "outputId": "3d0ff9e8-c0fb-4646-ae4b-e94788a47a9d"
      },
      "source": [
        "url =  baseUrl + \"PreProcessing/SentenceSplitterAndTokenize\"\n",
        "payload = u'''{\\\"text\\\": \\\"او دانشجو است. در ایران درس میخونه.\\\",\n",
        "\n",
        "    \\\"checkSlang\\\": true,\n",
        "\n",
        "    \\\"normalize\\\": true,\n",
        "\n",
        "    \\\"normalizerParams\\\": {\n",
        "\n",
        "        \\\"text\\\": \\\"don't care\\\",\n",
        "\n",
        "        \\\"replaceWildChar\\\": true,\n",
        "\n",
        "        \\\"replaceDigit\\\": true,\n",
        "\n",
        "        \\\"refineSeparatedAffix\\\": true,\n",
        "\n",
        "        \\\"refineQuotationPunc\\\": false\n",
        "\n",
        "    },\n",
        "\n",
        "    \\\"complexSentence\\\": true\n",
        "\n",
        "}'''\n",
        "print(callApi(url, payload, tokenKey))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[\"او\",\"دانشجو\",\"است\",\".\"],[\"در\",\"ایران\",\"درس\",\"می‌خواند\",\".\"]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud37VgbvQOvX"
      },
      "source": [
        "#  (Spell Correction) تصحیح خطای املایی"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqTx7t9sQOvY",
        "outputId": "bd7981e1-8e75-447d-ea22-4b97ad77eec5"
      },
      "source": [
        "url =  baseUrl + \"TextRefinement/SpellCorrector\"\n",
        "payload = u'''{\\\"text\\\": \\\"آب مبات خیلی چوشمزه ست\\\",\n",
        "\n",
        "            \\\"checkSlang\\\": true,\n",
        "\n",
        "            \\\"normalize\\\": true,\n",
        "\n",
        "            \\\"candidateCount\\\": 3}'''\n",
        "print(callApi(url, payload, tokenKey))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "آب {نبات,مبرات,مباد} {خیلی,خلیلی,تخیلی} {چوش مزه,خوشمزه} {ست,است}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcR-ePDhQOvb"
      },
      "source": [
        "# تبدیل محاوره به رسمی\n",
        "کلمات محاوره‌ای درون متن به شکل (معادل) رسمی آنها تبدیل می‌شود"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iokWf70fQOvd",
        "outputId": "8cfb4973-63bf-4200-82d5-94cf9a80d8bd"
      },
      "source": [
        "url =  baseUrl + \"TextRefinement/FormalConverter\"\n",
        "payload = u'''\"میخوام بگم\"'''\n",
        "print(callApi(url, payload, tokenKey))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "می‌خواهم بگویم\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmGPyRQ5QOvh"
      },
      "source": [
        "# تعیین برچسب نقش ادات سخن\n",
        "این تابع عملیات برچسب زنی نقش (اسم، ضمیر، صفت، قید، فعل، …) کلمات در جمله را انجام می دهد"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OSRsKBuQOvi",
        "outputId": "6d3f8c6f-83af-40a9-885e-7043c99b5400"
      },
      "source": [
        "url =  baseUrl + \"PosTagger/GetPos\"\n",
        "payload = u'\"او دانشجو در ایران است\"'\n",
        "result = json.loads(callApi(url, payload, tokenKey))\n",
        "for phrase in result:\n",
        "    print(\"(\"+phrase['word']+\",\"+phrase['tags']['POS']['item1']+\") \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(او,PRO) \n",
            "(دانشجو,N) \n",
            "(در,P) \n",
            "(ایران,N) \n",
            "(است,V) \n",
            "(.,) \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZ2fHvs6QOvj"
      },
      "source": [
        "# ریشه‌یابی کلمات یا بن‌واژه‌یاب"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsW135lzQOvk",
        "outputId": "bc96e615-8c62-4324-9af5-ed7d965d1fb4"
      },
      "source": [
        "url =  baseUrl + \"Stemmer/LemmatizeWords2Phrase\"\n",
        "payload = u'[\"دریانوردانی\", \"جزایر\", \"فرشتگان\", \"تنها\", \"کتابها\"]'\n",
        "result = json.loads(callApi(url, payload, tokenKey))\n",
        "for phrase in result:\n",
        "    print(\"(\"+phrase['word']+\":\"+phrase['firstRoot']+\") \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(دریانوردانی:دریانورد) \n",
            "(جزایر:جزیره) \n",
            "(فرشتگان:فرشته) \n",
            "(تنها:تنها) \n",
            "(کتابها:کتاب) \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUyBwr4_QOvp"
      },
      "source": [
        "# NER تشخیص موجودیت های نامدار "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YsIUMLdQOvq",
        "outputId": "28d5fcb0-ee02-431b-cf02-96c38ba6b19c"
      },
      "source": [
        "url =  baseUrl + \"NamedEntityRecognition/Detect\"\n",
        "payload = u'\"هانی محفوض به تحصیالت خود در دانشگاه اصفهان در ایران ادامه داد\"'\n",
        "result = json.loads(callApi(url, payload, tokenKey))\n",
        "for phrase in result:\n",
        "    print(\"(\"+phrase['word']+\",\"+phrase['tags']['NER']['item1']+\") \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(هانی,B-PER) \n",
            "(محفوض,I-PER) \n",
            "(به,O) \n",
            "(تحصیالت,O) \n",
            "(خود,O) \n",
            "(در,O) \n",
            "(دانشگاه,B-LOC) \n",
            "(اصفهان,I-LOC) \n",
            "(در,O) \n",
            "(ایران,B-LOC) \n",
            "(ادامه,O) \n",
            "(داد,O) \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLdI1leDQOvr"
      },
      "source": [
        "# استخراج مترادف‌ها\n",
        "این تابع کلمات هم‌معنی (معادل مفهومی) با کلمه ورودی در فرهنگ لغت‌های مختلف را برمی‌گرداند"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WCvJ6n4QOvs",
        "outputId": "fd062530-f691-4515-f3d4-9ff50ad62895"
      },
      "source": [
        "url =  baseUrl + \"TextSimilarity/ExtractSynonyms\"\n",
        "payload = u\"\\\"دوست\\\"\"\n",
        "print(callApi(url, payload, tokenKey))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"دوست\",\"آشنا\",\"تاش\",\"حبیب\",\"حریف\",\"حمیم\",\"خلیل\",\"یار\",\"همدم\",\"معشوق\",\"رفیق\",\"صدوق\",\"صدیق\",\"محب\",\"محبوب\",\"مصاحب\",\"معاشر\",\"ولی\",\"ولی‌\",\"دوستی\",\"ایاغ\",\"عیاق\",\"رفاقت\",\"ایاق\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS1eUPXrQOvu"
      },
      "source": [
        "# شناسایی نوع زبان"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo8zIshpQOvw",
        "outputId": "5770a804-c4ce-4503-81b2-9a160d882d91"
      },
      "source": [
        "url =  baseUrl + \"LanguageDetection/Predict\"\n",
        "payload = u'\"I go to school\"'\n",
        "print(callApi(url, payload, tokenKey))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "en\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAuGaE99QOvx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}